{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10VPNaEFqcbDiihAVyrxj5j29gJ0TL5sT",
      "authorship_tag": "ABX9TyM7tE9O1X7YGBNUdu+iKdzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoongthuck/R-E/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피처 추출"
      ],
      "metadata": {
        "id": "Ss0-YSHMoDRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kpop 데이터셋 피처 추출"
      ],
      "metadata": {
        "id": "7n0TICJ4oGyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/EX3exp/Kpop-lyric-datasets.git"
      ],
      "metadata": {
        "id": "65xKcK1FnMTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wnC7IndzoY82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# data load\n",
        "song_df = []\n",
        "for year in range(2000,2024):\n",
        "  for month in range(1,13):\n",
        "    for rank in range(1,51):\n",
        "      file_path = f'/content/Kpop-lyric-datasets/melon/monthly-chart/melon-{year}/melon-{year}-{month:02d}/melon-monthly_{year}-{month:02d}_{rank:02d}.json'\n",
        "\n",
        "      if not os.path.exists(file_path):\n",
        "        continue\n",
        "\n",
        "      try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "          song_json = json.load(f)\n",
        "        read_artist = song_json['artist']\n",
        "        read_title = song_json['song_name']\n",
        "        read_lyric = song_json['lyrics']['lines']\n",
        "\n",
        "        song_df.append({\n",
        "          \"artist\": read_artist,\n",
        "          \"title\": read_title,\n",
        "          \"lyric\": read_lyric\n",
        "        })\n",
        "\n",
        "      except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "song_df = pd.DataFrame(song_df)\n",
        "song_df.to_csv('lyric_df.csv')"
      ],
      "metadata": {
        "id": "Ug-qpU5wokz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, sys, time, argparse\n",
        "from typing import Dict, Iterable, List, Optional, Tuple\n",
        "import requests\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pandas as pd\n",
        "\n",
        "API = \"https://api.deezer.com\""
      ],
      "metadata": {
        "id": "F8qAZysXotq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize(name):\n",
        "    return re.sub(r'[\\\\/:*?\"<>|\\x00-\\x1F]+', '', name).strip()[:200]\n",
        "\n",
        "def ensure_dir(path):\n",
        "    if path and not os.path.exists(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def fetch_json(url, params=None, retry=3, timeout = 15):\n",
        "    for i in range(retry):\n",
        "        try:\n",
        "            r = requests.get(url, params=params, timeout=timeout)\n",
        "            if r.status_code == 200:\n",
        "                try:\n",
        "                    return r.json()\n",
        "                except ValueError:\n",
        "                    print(f\"[debug] non-JSON: {r.text[:200]}\", file=sys.stderr)\n",
        "            else:\n",
        "                print(f\"[warn] HTTP {r.status_code} {r.url}\", file=sys.stderr)\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"[warn] {e}\", file=sys.stderr)\n",
        "        time.sleep(1.0 * (i + 1))\n",
        "    return {}"
      ],
      "metadata": {
        "id": "HpA3xz24ooY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def track_item_from_id(tid: int) -> Optional[dict]:\n",
        "    j = fetch_json(f\"{API}/track/{tid}\")\n",
        "    return j if j and j.get(\"id\") else None\n",
        "\n",
        "def track_items_from_album(aid: int) -> Iterable[dict]:\n",
        "    j = fetch_json(f\"{API}/album/{aid}\")\n",
        "    tracks = j.get(\"tracks\", {})\n",
        "    for t in tracks.get(\"data\", []):\n",
        "        yield t\n",
        "\n",
        "def track_items_from_playlist(pid: int) -> Iterable[dict]:\n",
        "    j = fetch_json(f\"{API}/playlist/{pid}\")\n",
        "    tracks = j.get(\"tracks\", {})\n",
        "    if \"data\" in tracks:\n",
        "        for t in tracks[\"data\"]:\n",
        "            yield t\n",
        "        next_url = tracks.get(\"next\")\n",
        "        while next_url:\n",
        "            page = fetch_json(next_url)\n",
        "            for t in page.get(\"data\", []):\n",
        "                yield t\n",
        "            next_url = page.get(\"next\")\n",
        "\n",
        "def track_items_from_artist_top(artist_id: int, limit: int = 50) -> Iterable[dict]:\n",
        "    j = fetch_json(f\"{API}/artist/{artist_id}/top\", params={\"limit\": limit})\n",
        "    for t in j.get(\"data\", []):\n",
        "        yield t\n",
        "\n",
        "def search_tracks(query: str, limit: int = 5) -> Iterable[dict]:\n",
        "    j = fetch_json(f\"{API}/search\", params={\"q\": query, \"limit\": limit})\n",
        "    for t in j.get(\"data\", []):\n",
        "        yield t"
      ],
      "metadata": {
        "id": "w8kDDJIsoxbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_filename(t: dict, outdir: str) -> str:\n",
        "    artist = t.get(\"artist\", {}).get(\"name\", \"Unknown Artist\")\n",
        "    title  = t.get(\"title\", f\"track-{t.get('id','unknown')}\")\n",
        "    return os.path.join(outdir, sanitize(f\"{artist} - {title} (preview).mp3\"))\n",
        "\n",
        "def download_preview(t: dict, outdir: str, overwrite: bool = False) -> Optional[str]:\n",
        "    url = t.get(\"preview\")\n",
        "    tid = t.get(\"id\")\n",
        "    if not url:\n",
        "        print(f\"[skip] preview 없음 (track id: {tid})\", file=sys.stderr)\n",
        "        return None\n",
        "    ensure_dir(outdir)\n",
        "    dest = choose_filename(t, outdir)\n",
        "    if os.path.exists(dest) and not overwrite:\n",
        "        print(f\"[keep] 이미 있음: {os.path.basename(dest)}\")\n",
        "        return dest\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=30) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(dest, \"wb\") as f:\n",
        "                for ch in r.iter_content(8192):\n",
        "                    if ch: f.write(ch)\n",
        "        print(f\"[ok] saved: {os.path.basename(dest)}\")\n",
        "        return dest\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"[err] 다운로드 실패: {e}\", file=sys.stderr)\n",
        "        return None"
      ],
      "metadata": {
        "id": "p9uQWJugoyaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "# Mode: Krumhansl–Kessler\n",
        "_PITCHES = np.array([\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"])\n",
        "_KK_MAJOR = np.array([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], dtype=float)\n",
        "_KK_MINOR = np.array([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], dtype=float)\n",
        "\n",
        "def _best_key_from_chroma_mean(chroma_mean: np.ndarray) -> Tuple[str, str, float]:\n",
        "    def z(x):\n",
        "        x = np.asarray(x, float)\n",
        "        return (x - x.mean()) / (x.std() + 1e-8)\n",
        "\n",
        "    cm = z(chroma_mean)\n",
        "    best_corr, best_key, best_mode = -np.inf, None, None\n",
        "\n",
        "    for shift in range(12):\n",
        "        maj = np.roll(_KK_MAJOR, shift)\n",
        "        minr = np.roll(_KK_MINOR, shift)\n",
        "        cmaj = np.corrcoef(cm, z(maj))[0,1]\n",
        "        cmin = np.corrcoef(cm, z(minr))[0,1]\n",
        "        if cmaj > best_corr:\n",
        "            best_corr = cmaj\n",
        "            best_mode = \"major\"\n",
        "        if cmin > best_corr:\n",
        "            best_corr = cmin\n",
        "            best_mode = \"minor\"\n",
        "\n",
        "    return float(best_corr)"
      ],
      "metadata": {
        "id": "hGKA2sBWozXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio_path: str, sr_target: int = 22050):\n",
        "    y, sr = librosa.load(audio_path, sr=sr_target, mono=True)\n",
        "\n",
        "    y_h = librosa.effects.harmonic(y)\n",
        "    y_p = librosa.effects.percussive(y)\n",
        "\n",
        "    tempo, _ = librosa.beat.beat_track(y=y_p, sr=sr)\n",
        "\n",
        "    rms = librosa.feature.rms(y=y).flatten()\n",
        "    rms_db = librosa.amplitude_to_db(rms, ref=1.0)\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfcc_mean = mfcc.mean(axis=1)\n",
        "    mfcc_std  = mfcc.std(axis=1)\n",
        "\n",
        "    chroma = librosa.feature.chroma_cqt(y=y_h, sr=sr)\n",
        "    chroma_mean = chroma.mean(axis=1)\n",
        "\n",
        "    corr = _best_key_from_chroma_mean(chroma_mean)\n",
        "\n",
        "    return {\n",
        "        \"tempo_bpm\": float(tempo[0]),\n",
        "        \"rms_mean\": float(rms.mean()),\n",
        "        \"rms_std\": float(rms.std()),\n",
        "        \"rms_db_mean\": float(rms_db.mean()),\n",
        "        \"rms_db_std\": float(rms_db.std()),\n",
        "        \"mfcc_mean\": mfcc_mean,\n",
        "        \"mfcc_std\":  mfcc_std,\n",
        "        \"chroma_mean\": chroma_mean,\n",
        "        \"mode_conf\": corr\n",
        "    }"
      ],
      "metadata": {
        "id": "JEq2T_Fqo0uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_to_row(meta: dict, feats: Dict[str, object], path: str) -> dict:\n",
        "    row = {\n",
        "        \"tempo_bpm\": feats[\"tempo_bpm\"],\n",
        "        \"rms_mean\": feats[\"rms_mean\"],\n",
        "        \"rms_std\": feats[\"rms_std\"],\n",
        "        \"rms_db_mean\": feats[\"rms_db_mean\"],\n",
        "        \"rms_db_std\": feats[\"rms_db_std\"],\n",
        "        \"mode_conf\": feats[\"mode_conf\"],\n",
        "    }\n",
        "    # MFCC mean/std\n",
        "    for i, v in enumerate(np.asarray(feats[\"mfcc_mean\"]).tolist()):\n",
        "        row[f\"mfcc_mean_{i}\"] = float(v)\n",
        "    for i, v in enumerate(np.asarray(feats[\"mfcc_std\"]).tolist()):\n",
        "        row[f\"mfcc_std_{i}\"] = float(v)\n",
        "    # Chroma mean\n",
        "    for pitch, v in zip(_PITCHES, np.asarray(feats[\"chroma_mean\"]).tolist()):\n",
        "        row[f\"chroma_{pitch}\"] = float(v)\n",
        "    return row"
      ],
      "metadata": {
        "id": "RKJTqvz8o2SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_items(args) -> List[dict]:\n",
        "    items: List[dict] = []\n",
        "    if args.track_id:\n",
        "        t = track_item_from_id(args.track_id)\n",
        "        if t: items = [t]\n",
        "    elif args.album_id:\n",
        "        items = list(track_items_from_album(args.album_id))\n",
        "    elif args.playlist_id:\n",
        "        items = list(track_items_from_playlist(args.playlist_id))\n",
        "    elif args.artist_id:\n",
        "        items = list(track_items_from_artist_top(args.artist_id, limit=args.limit))\n",
        "    elif args.search:\n",
        "        items = list(search_tracks(args.search, limit=args.limit))\n",
        "    else:\n",
        "        print(\"[err] 소스 지정 x\", file=sys.stderr)\n",
        "        sys.exit(2)\n",
        "\n",
        "    if args.title and args.artist and args.search:\n",
        "        best = select_best_match(items, args.title, args.artist)\n",
        "        if best:\n",
        "            items = [best]\n",
        "    return items\n",
        "\n",
        "def pipeline(args) -> pd.DataFrame:\n",
        "    ensure_dir(args.outdir)\n",
        "    items = collect_items(args)\n",
        "    if not items:\n",
        "        print(\"[warn] 처리할 트랙이 없음\", file=sys.stderr)\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    rows = []\n",
        "    for t in items[: args.limit if args.limit else None]:\n",
        "        if not t.get(\"preview\"):\n",
        "            print(f\"[skip] preview 없음 (title={t.get('title')})\", file=sys.stderr)\n",
        "            continue\n",
        "        mp3 = download_preview(t, args.outdir, overwrite=args.overwrite)\n",
        "        if not mp3:\n",
        "            continue\n",
        "        try:\n",
        "            feats = extract_features(mp3, sr_target=args.sr)\n",
        "            rows.append({\n",
        "                **features_to_row(t, feats, mp3),\n",
        "                'title': args.title,\n",
        "                'artist': args.artist\n",
        "                })\n",
        "            print('추출 성공')\n",
        "        except Exception as e:\n",
        "            print(f\"[err] failed: {e}\", file=sys.stderr)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "1paT5xxEo5Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_query_from_title_artist(title: str, artist: str) -> str:\n",
        "  t = title.replace('\"', '\\\\\"').strip()\n",
        "  a = artist.replace('\"', '\\\\\"').strip()\n",
        "  return f'artist:\"{a}\" track:\"{t}\"'\n",
        "\n",
        "\n",
        "def _normalize_text(s: str) -> str:\n",
        "    s = s or \"\"\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", s)\n",
        "    s = re.sub(r\"\\bfeat(?:uring)?\\.?\\b.*\", \"\", s)\n",
        "    s = re.sub(r\"[^a-z0-9가-힣]+\", \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def select_best_match(items: List[dict], title: str, artist: str) -> Optional[dict]:\n",
        "    if not items:\n",
        "        return None\n",
        "    nt = _normalize_text(title)\n",
        "    na = _normalize_text(artist)\n",
        "    best, best_score = None, -1.0\n",
        "    for t in items:\n",
        "        t_title = t.get(\"title\", \"\")\n",
        "        t_artist = (t.get(\"artist\") or {}).get(\"name\", \"\")\n",
        "        score = 0.0\n",
        "        tt = _normalize_text(t_title)\n",
        "        ta = _normalize_text(t_artist)\n",
        "        if tt == nt: score += 2.0\n",
        "        elif nt and nt in tt: score += 1.0\n",
        "        if ta == na: score += 2.0\n",
        "        elif na and na in ta: score += 1.0\n",
        "        if t.get(\"preview\"): score += 0.5\n",
        "        if score > best_score:\n",
        "            best, best_score = t, score\n",
        "    return best"
      ],
      "metadata": {
        "id": "ddO5GmDSo6iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(chart, args=None):\n",
        "    ap = argparse.ArgumentParser(description=\"Deezer 미리듣기 → MFCC/Chroma/Mode/BPM/RMS + DataFrame/CSV\")\n",
        "    src = ap.add_mutually_exclusive_group(required=False)\n",
        "    src.add_argument(\"--track-id\", type=int)\n",
        "    src.add_argument(\"--album-id\", type=int)\n",
        "    src.add_argument(\"--playlist-id\", type=int)\n",
        "    src.add_argument(\"--artist-id\", type=int)\n",
        "    src.add_argument(\"--search\", type=str)\n",
        "\n",
        "    ap.add_argument(\"--title\", type=str)\n",
        "    ap.add_argument(\"--artist\", type=str)\n",
        "    ap.add_argument(\"-o\", \"--outdir\", default=\"previews\")\n",
        "    ap.add_argument(\"-n\", \"--limit\", type=int, default=10)\n",
        "    ap.add_argument(\"--overwrite\", action=\"store_true\")\n",
        "    ap.add_argument(\"--sr\", type=int, default=22050)\n",
        "    ap.add_argument(\"--csv\", type=str, default=\"deezer_features_total.csv\")\n",
        "    ap.add_argument(\"--csv-encoding\", type=str, default=\"utf-8-sig\")\n",
        "\n",
        "    parsed, _unknown = ap.parse_known_args(args)\n",
        "\n",
        "    csv_path = parsed.csv\n",
        "    written = os.path.exists(csv_path)\n",
        "\n",
        "    dfs = []\n",
        "\n",
        "    for idx in range(len(chart)):\n",
        "        title = chart['title'].iloc[idx]\n",
        "        artist = chart['artist'].iloc[idx]\n",
        "        print(f\"\\n [{idx+1}/{len(chart)}] {artist} - {title}\")\n",
        "\n",
        "        parsed.title = title\n",
        "        parsed.artist = artist\n",
        "        parsed.search = build_query_from_title_artist(title, artist)\n",
        "\n",
        "        try:\n",
        "            df = pipeline(parsed)\n",
        "            if df is not None and not df.empty:\n",
        "                dfs.append(df)\n",
        "            else:\n",
        "                print(f\"[skip] {artist} - {title}: 분석 결과 없음\")\n",
        "        except Exception as e:\n",
        "            print(f\"[err] {artist} - {title} 실패: {e}\")\n",
        "\n",
        "        # auto save\n",
        "        if (idx + 1) % 4 == 0 and dfs:\n",
        "            merged = pd.concat(dfs, ignore_index=True)\n",
        "            merged.to_csv(csv_path, mode='a', header=not written, index=False, encoding=parsed.csv_encoding)\n",
        "            written = True\n",
        "            dfs = []\n",
        "            print(f\"[autosave] {idx+1}곡까지 저장\")\n",
        "\n",
        "    # save\n",
        "    if dfs:\n",
        "        merged = pd.concat(dfs, ignore_index=True)\n",
        "        merged.to_csv(csv_path, mode='a', header=not written, index=False, encoding=parsed.csv_encoding)\n",
        "        print(f\"\\n전체 {len(chart)}곡 피처 저장\")\n",
        "        return merged\n",
        "    else:\n",
        "        print(\"\\n[warn] 트랙 데이터 없음\")\n",
        "        return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "leXDL6n_o8wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(song_df)"
      ],
      "metadata": {
        "id": "RhJCbdLCo_il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deam 피처 추출"
      ],
      "metadata": {
        "id": "2uMDUOfioG_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sw20vtxxnnIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, sys, time, argparse\n",
        "from typing import Dict, Iterable, List, Optional, Tuple\n",
        "import requests\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DtT5NZjXnqdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_dir(path):\n",
        "    if path and not os.path.exists(path):\n",
        "        os.makedirs(path, exist_ok=True)"
      ],
      "metadata": {
        "id": "Uj4LlPU5ntFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "# Mode: Krumhansl–Kessler\n",
        "_PITCHES = np.array([\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"])\n",
        "_KK_MAJOR = np.array([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], dtype=float)\n",
        "_KK_MINOR = np.array([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], dtype=float)\n",
        "\n",
        "def _best_key_from_chroma_mean(chroma_mean: np.ndarray) -> Tuple[str, str, float]:\n",
        "    def z(x):\n",
        "        x = np.asarray(x, float)\n",
        "        return (x - x.mean()) / (x.std() + 1e-8)\n",
        "\n",
        "    cm = z(chroma_mean)\n",
        "    best_corr, best_key, best_mode = -np.inf, None, None\n",
        "\n",
        "    for shift in range(12):\n",
        "        maj = np.roll(_KK_MAJOR, shift)\n",
        "        minr = np.roll(_KK_MINOR, shift)\n",
        "        cmaj = np.corrcoef(cm, z(maj))[0,1]\n",
        "        cmin = np.corrcoef(cm, z(minr))[0,1]\n",
        "        if cmaj > best_corr:\n",
        "            best_corr = cmaj\n",
        "            best_mode = \"major\"\n",
        "        if cmin > best_corr:\n",
        "            best_corr = cmin\n",
        "            best_mode = \"minor\"\n",
        "\n",
        "    return float(best_corr)\n"
      ],
      "metadata": {
        "id": "2IjetCFUnuIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio_path: str, sr_target: int = 22050):\n",
        "    y, sr = librosa.load(audio_path, duration=30.0, sr=sr_target, mono=True)\n",
        "\n",
        "    y_h = librosa.effects.harmonic(y)\n",
        "    y_p = librosa.effects.percussive(y)\n",
        "\n",
        "    tempo, _ = librosa.beat.beat_track(y=y_p, sr=sr)\n",
        "\n",
        "    rms = librosa.feature.rms(y=y).flatten()\n",
        "    rms_db = librosa.amplitude_to_db(rms, ref=1.0)\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfcc_mean = mfcc.mean(axis=1)\n",
        "    mfcc_std  = mfcc.std(axis=1)\n",
        "\n",
        "    chroma = librosa.feature.chroma_cqt(y=y_h, sr=sr)\n",
        "    chroma_mean = chroma.mean(axis=1)\n",
        "\n",
        "    corr = _best_key_from_chroma_mean(chroma_mean)\n",
        "\n",
        "    return {\n",
        "        \"tempo_bpm\": float(tempo[0]),\n",
        "        \"rms_mean\": float(rms.mean()),\n",
        "        \"rms_std\": float(rms.std()),\n",
        "        \"rms_db_mean\": float(rms_db.mean()),\n",
        "        \"rms_db_std\": float(rms_db.std()),\n",
        "        \"mfcc_mean\": mfcc_mean,\n",
        "        \"mfcc_std\":  mfcc_std,\n",
        "        \"chroma_mean\": chroma_mean,\n",
        "        \"mode_conf\": corr\n",
        "    }"
      ],
      "metadata": {
        "id": "idxhLeLan0rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_to_row(feats: Dict[str, object], path: str) -> dict:\n",
        "    row = {\n",
        "       \"tempo_bpm\": feats[\"tempo_bpm\"],\n",
        "        \"rms_mean\": feats[\"rms_mean\"],\n",
        "        \"rms_std\": feats[\"rms_std\"],\n",
        "        \"rms_db_mean\": feats[\"rms_db_mean\"],\n",
        "        \"rms_db_std\": feats[\"rms_db_std\"],\n",
        "        \"mode_conf\": feats[\"mode_conf\"],\n",
        "    }\n",
        "    # MFCC mean/std\n",
        "    for i, v in enumerate(np.asarray(feats[\"mfcc_mean\"]).tolist()):\n",
        "        row[f\"mfcc_mean_{i}\"] = float(v)\n",
        "    for i, v in enumerate(np.asarray(feats[\"mfcc_std\"]).tolist()):\n",
        "        row[f\"mfcc_std_{i}\"] = float(v)\n",
        "    # Chroma mean\n",
        "    for pitch, v in zip(_PITCHES, np.asarray(feats[\"chroma_mean\"]).tolist()):\n",
        "        row[f\"chroma_{pitch}\"] = float(v)\n",
        "    return row"
      ],
      "metadata": {
        "id": "CQsj66oqn1Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(args) -> pd.DataFrame:\n",
        "    ensure_dir(args.outdir)\n",
        "\n",
        "    rows = []\n",
        "    mp3 = f'/content/drive/MyDrive/VAD/song_data/audio/{args.id}.mp3'\n",
        "\n",
        "    try:\n",
        "        feats = extract_features(mp3, sr_target=args.sr)\n",
        "        rows.append({\n",
        "            **features_to_row(feats, mp3),\n",
        "            'id': args.id,\n",
        "            })\n",
        "        print('추출 성공')\n",
        "    except Exception as e:\n",
        "        print(f\"[err] feature extraction failed: {e}\", file=sys.stderr)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "1mmEMH8Xn2ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(chart, args=None):\n",
        "    ap = argparse.ArgumentParser(description=\"Deezer 미리듣기 → MFCC/Chroma/Mode/BPM/RMS + DataFrame/CSV\")\n",
        "    src = ap.add_mutually_exclusive_group(required=False)\n",
        "    ap.add_argument(\"--id\", type=str)\n",
        "    ap.add_argument(\"-o\", \"--outdir\", default=\"audio\")\n",
        "    ap.add_argument(\"-n\", \"--limit\", type=int, default=10)\n",
        "    ap.add_argument(\"--overwrite\", action=\"store_true\")\n",
        "    ap.add_argument(\"--sr\", type=int, default=22050)\n",
        "    ap.add_argument(\"--csv\", type=str, default=None)\n",
        "    ap.add_argument(\"--csv-encoding\", type=str, default=\"utf-8\")\n",
        "\n",
        "    parsed, _unknown = ap.parse_known_args(args)\n",
        "\n",
        "    dfs = []\n",
        "\n",
        "    for idx in range(len(chart)):\n",
        "        id = chart['song_id'].iloc[idx]\n",
        "        print(f\"\\n [{idx+1}/{len(chart)}] id:{id}\")\n",
        "\n",
        "        parsed.id = id\n",
        "\n",
        "        try:\n",
        "            df = pipeline(parsed)\n",
        "            if df is not None and not df.empty:\n",
        "                dfs.append(df)\n",
        "            else:\n",
        "                print(f\"[skip] {id}: 분석 결과 없음\")\n",
        "        except Exception as e:\n",
        "            print(f\"[err] {id} 실패: {e}\")\n",
        "\n",
        "        if (idx + 1) % 20 == 0 and dfs:\n",
        "            written = os.path.exists('/content/drive/MyDrive/VAD/deezer_features_total.csv')\n",
        "            merged = pd.concat(dfs, ignore_index=True)\n",
        "            merged.to_csv(\"/content/drive/MyDrive/VAD/deezer_features_total.csv\", mode='a', header=not written, index=False, encoding=\"utf-8-sig\")\n",
        "            print(f\"[autosave] {idx+1}곡 중간 저장 완료 ({len(dfs)} DataFrames)\")\n",
        "            dfs.clear()\n",
        "\n",
        "    if dfs:\n",
        "        written = os.path.exists('/content/drive/MyDrive/VAD/deezer_features_total.csv')\n",
        "        merged = pd.concat(dfs, ignore_index=True)\n",
        "        merged.to_csv(\"/content/drive/MyDrive/VAD/deezer_features_total.csv\", mode='a', header=not written, index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"\\n전체 {len(dfs)}곡 저장 완료\")\n",
        "        return merged\n",
        "    else:\n",
        "        print(\"\\n[warn] 유효한 트랙 데이터가 없습니다.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "XR4aBSU_n6hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_feat_set = pd.read_csv('song_data/vad/static_annotations_averaged_songs_1_2000.csv')"
      ],
      "metadata": {
        "id": "pTnkOKKNn-Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(audio_feat_set.loc)"
      ],
      "metadata": {
        "id": "WRcZTuZ_oA5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emobank 번역\n"
      ],
      "metadata": {
        "id": "Pf2CWHFJnWfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep-translator"
      ],
      "metadata": {
        "id": "pckLNGlRybvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time, os\n",
        "from deep_translator import GoogleTranslator"
      ],
      "metadata": {
        "id": "xOQZypxDyaF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y6DctzDMyfAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Emobank/lyric_df_translated.csv'\n",
        "checkpoint_path = '/content/drive/MyDrive/Emobank/lyric_df_checkpoint.csv'\n",
        "\n",
        "batch_size = 50\n",
        "save_every = 200\n",
        "\n",
        "# load\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/JULIELab/EmoBank/master/corpus/emobank.csv')\n",
        "\n",
        "if 'trans' not in df.columns:\n",
        "    df['trans'] = ''\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    df_cp = pd.read_csv(checkpoint_path)\n",
        "    if len(df_cp) == len(df):\n",
        "        df = df_cp\n",
        "        print(f\"번역된 {(df['trans'].astype(str).str.strip() != '').sum()}행\")\n",
        "\n",
        "translator = GoogleTranslator(source='auto', target='ko')\n",
        "\n",
        "# translation\n",
        "n = len(df)\n",
        "for i in range(n):\n",
        "    current = str(df.loc[i, 'trans']).strip()\n",
        "\n",
        "    # skip\n",
        "    if current != '' and current.lower() != 'nan':\n",
        "        continue\n",
        "\n",
        "    text = str(df.loc[i, 'text'])\n",
        "    if text.strip() == '' or text.lower() == 'nan':\n",
        "        df.loc[i, 'trans'] = ''\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        if len(text) > 4500:\n",
        "            text = text[:4500]\n",
        "\n",
        "        df.loc[i, 'trans'] = translator.translate(text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{i} 오류: {e}\")\n",
        "        df.loc[i, 'trans'] = ''\n",
        "        time.sleep(3)\n",
        "        continue\n",
        "\n",
        "    if (i + 1) % batch_size == 0:\n",
        "        done = (df['trans'].astype(str).str.strip() != '').sum()\n",
        "        print(f\"{i+1}/{n}행 완료\")\n",
        "        time.sleep(0.3)\n",
        "\n",
        "    # auto save\n",
        "    if (i + 1) % save_every == 0:\n",
        "        df.to_csv(checkpoint_path, index=False)\n",
        "        print(f\"{i+1}행 저장\")\n",
        "\n",
        "# save\n",
        "df.to_csv(save_path, index=False)\n",
        "df.to_csv(checkpoint_path, index=False)\n",
        "print(f\"번역된 행: {(df['trans'].astype(str).str.strip() != '').sum()}개\")"
      ],
      "metadata": {
        "id": "psAOST0FyT6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}